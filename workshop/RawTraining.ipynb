{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi everyone! In this notebook we will learn how to train a model with eager mode of Tensorflow 2. For teaching objectives, we just focus on implementing the training phase with eager mode. A more comprehensive training procedure is given in KerasTraining.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sth for colab\n",
    "\"\"\"\n",
    "%cd /content\n",
    "!git clone https://github.com/MSBD-5001/Lecture-Materials\n",
    "%cd Lecture-Materials/workshop\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset, class_names, predicts=None):\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.8, wspace=0.4)\n",
    "    for i, (image, label) in enumerate(dataset):\n",
    "        if i>= 9: \n",
    "            break\n",
    "        if image.shape[-1] == 1:\n",
    "            revised_image = np.squeeze(image)\n",
    "        else:\n",
    "            revised_image = image\n",
    "        axes.flat[i].imshow(revised_image)\n",
    "        # Name of the true class.\n",
    "        label_name = class_names[label]\n",
    "        \n",
    "        # Show true and predicted classes.\n",
    "        if predicts is None:\n",
    "            axes.flat[i].set_xlabel(\"True : {0}\".format(label_name))\n",
    "        else:\n",
    "            predict_name = class_names[predicts[i]]\n",
    "            axes.flat[i].set_xlabel(\"True: {0}\\nPred: {1}\".format(label_name, predict_name))\n",
    "        # Remove ticks from the plot.\n",
    "        axes.flat[i].set_xticks([])\n",
    "        axes.flat[i].set_yticks([])\n",
    "    while(i < 8):\n",
    "        i += 1\n",
    "        axes.flat[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a simple Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary components in training procedure: <b>Optimizer</b>, <b>loss</b> and <b>metrics</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use tf.GradientTape to trace operations for computing gradients later.\n",
    "\n",
    "All forward-pass operations get recorded to a \"tape\". To compute the gradient, play the tape backwards and then discard. So a particular tf.GradientTape can only compute gradient once; subsequent calls throw a runtime error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss = compute_loss(y, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    compute_accuracy(y, logits)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function annotation will construct a graph by packing operations in the function, which may reduce the running time. However, more time is needed for initializing the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subTrainDataset = trainDataset.shuffle(buffer_size=1024).batch(64)\n",
    "subTestDataset = testDataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    compute_accuracy.reset_states()\n",
    "    for x,y in subTrainDataset:\n",
    "        step += 1\n",
    "        loss = train_one_step(cnnModel, optimizer, x, y)\n",
    "        if step % 50 == 0:\n",
    "            tf.print(\"Loss: \", loss, \"Accuracy on training data:\", compute_accuracy.result())\n",
    "    compute_accuracy.reset_states()\n",
    "    \n",
    "    for x, y in subTestDataset:\n",
    "        logits = cnnModel(x, training=False)\n",
    "        compute_accuracy(y, logits)\n",
    "    test_acc = compute_accuracy.result()\n",
    "    print(\"Accuracy on testing data: %.4f\" % (float(test_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = tf.argmax(cnnModel.predict(trainDataset.take(9).batch(9)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(trainDataset, class_names, predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
