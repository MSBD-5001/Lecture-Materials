{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./components.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):  \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        # load the files \n",
    "        filenames = []\n",
    "        labels = []\n",
    "        for filename in os.listdir(img_dir):\n",
    "            filenames.append(filename)\n",
    "            if filename.startswith(\"bird\"):\n",
    "                labels.append(0)\n",
    "            elif filename.startswith(\"cat\"):\n",
    "                labels.append(1)\n",
    "            elif filename.startswith(\"dog\"):\n",
    "                labels.append(2)\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_dataset = CustomImageDataset(\"./data/pets\",transform = Compose([ToTensor(), Resize((28,28))]))\n",
    "train_size = int(0.8 * len(pet_dataset))\n",
    "test_size = len(pet_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(pet_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "Here we try two different neural networks: \n",
    "- Simple model with some convolutional layers;\n",
    "- A pretrained classical convolutional neural network architecture: ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "    \n",
    "# Define model\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6,12,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(192, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv_stack(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "conv_model = ConvNN().to(device)\n",
    "print(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, dataset and dataloader for vgg model\n",
    "\n",
    "resnet_model = models.resnet18(pretrained=True).to(device)\n",
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = Compose([ToTensor(), Resize((224,224)), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "pet_dataset_resnet = CustomImageDataset(\"./data/pets\",transform = resnet_transform)\n",
    "train_size = int(0.8 * len(pet_dataset_resnet))\n",
    "test_size = len(pet_dataset_resnet) - train_size\n",
    "\n",
    "train_dataset_resnet, test_dataset_resnet = torch.utils.data.random_split(pet_dataset_resnet, [train_size, test_size])\n",
    "\n",
    "train_dataloader_resnet = DataLoader(train_dataset_resnet, batch_size=6, shuffle=True)\n",
    "test_dataloader_resnet = DataLoader(test_dataset_resnet, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 3)\n",
    "resnet_model = resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need a `loss function` and an `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = resnet_model\n",
    "trainloader = train_dataloader_resnet\n",
    "testloader = test_dataloader_resnet\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n",
    "backpropagates the prediction error to adjust the model's parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    correct, train_loss = 0, 0 \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    correct /= size\n",
    "    train_loss /= num_batches\n",
    "    return train_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model's performance against the test dataset to ensure it is learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() \n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n",
    "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
    "accuracy increase and the loss decrease with every epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    train_loss, train_acc = train(trainloader, model, loss_fn, optimizer)\n",
    "    test_loss, test_acc = test(testloader, model, loss_fn)\n",
    "    if t%1 == 0:\n",
    "        print(f\"Epoch {t}:\")\n",
    "        print(f\"Train Error. Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f}\")\n",
    "        print(f\"Test Error. Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "\n",
    "classes = [\"bird\", \"cat\", \"dog\"]\n",
    "model.eval()\n",
    "x, labels = next(iter(testloader))\n",
    "\n",
    "figure = plt.figure(figsize=(8, 6))\n",
    "cols, rows = 3, 2\n",
    "with torch.no_grad():\n",
    "    preds = model(x)\n",
    "correct = 0\n",
    "for i in range(len(preds)):\n",
    "    predicted, actual = classes[preds[i].argmax()], classes[labels[i]]\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "    img = x[i]\n",
    "    \"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).reshape((3,1,1))\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).reshape((3,1,1))\n",
    "    img = std * img + mean\"\"\"\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i + 1)\n",
    "    plt.title(f\"Actual: {actual}, Pred: {predicted}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(ToPILImage()(img))\n",
    "print(f\"accuracy: %i/%i.\"% ( correct,  len(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "-------------\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models\n",
    "----------------------------\n",
    "\n",
    "The process for loading a model includes re-creating the model structure and loading\n",
    "the state dictionary into it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
